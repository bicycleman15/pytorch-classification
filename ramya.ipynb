{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0533331669000a43511796226c0ff0dc9c285bf5a1783fa2d13045c1d50bcdf1d",
   "display_name": "Python 3.7.9 64-bit ('foggy': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, depth, num_classes=1000, block_name='BasicBlock'):\n",
    "        super(ResNet, self).__init__()\n",
    "        # Model type specifies number of layers for CIFAR-10 model\n",
    "        if block_name.lower() == 'basicblock':\n",
    "            assert (depth - 2) % 6 == 0, 'When use basicblock, depth should be 6n+2, e.g. 20, 32, 44, 56, 110, 1202'\n",
    "            n = (depth - 2) // 6\n",
    "            block = BasicBlock\n",
    "        elif block_name.lower() == 'bottleneck':\n",
    "            assert (depth - 2) % 9 == 0, 'When use bottleneck, depth should be 9n+2, e.g. 20, 29, 47, 56, 110, 1199'\n",
    "            n = (depth - 2) // 9\n",
    "            block = Bottleneck\n",
    "        else:\n",
    "            raise ValueError('block_name shoule be Basicblock or Bottleneck')\n",
    "\n",
    "\n",
    "        self.inplanes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 16, n)\n",
    "        self.layer2 = self._make_layer(block, 32, n, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, n, stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)    # 32x32\n",
    "\n",
    "        x = self.layer1(x)  # 32x32\n",
    "        x = self.layer2(x)  # 16x16\n",
    "        x = self.layer3(x)  # 8x8\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet32(**kwargs):\n",
    "    model = ResNet(depth=32, **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# @neelabh17 implementation\n",
    "\n",
    "\n",
    "class CCELossFast(torch.nn.Module):\n",
    "    def __init__(self, n_classes, n_bins = 10, mode = \"eval\", loss_type = \"sce\"):\n",
    "        '''\n",
    "        deprecated info ignore!!\n",
    "        output = [n_Class, h , w] np array: The complete probability vector of an image\n",
    "        target = [h , w] np array: The GT for the image\n",
    "        n_bins = [h , w] np array: Number of bins for the Calibration division\n",
    "\n",
    "        '''\n",
    "        super(CCELossFast,self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.n_bins = n_bins\n",
    "        self.mode = mode\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "\n",
    "        self.createBins()\n",
    "\n",
    "        self.no_pred_tot = torch.zeros(self.n_classes, self.n_bins).cuda()\n",
    "        self.no_acc_tot = torch.zeros(self.n_classes, self.n_bins).cuda()\n",
    "        self.conf_sum_tot = torch.zeros(self.n_classes, self.n_bins).cuda()\n",
    "\n",
    "    def reset(self):\n",
    "        self.no_pred_tot = torch.zeros(self.n_classes, self.n_bins).cuda()\n",
    "        self.no_acc_tot = torch.zeros(self.n_classes, self.n_bins).cuda()\n",
    "        self.conf_sum_tot = torch.zeros(self.n_classes, self.n_bins).cuda()\n",
    "\n",
    "\n",
    "    def forward(self , output, target):\n",
    "        '''\n",
    "        imp info!! dont ignore\n",
    "        output = [batch, n_Class] np array: The complete logit vector of an image \n",
    "\n",
    "        target = [batch] np array: The GT for the image\n",
    "\n",
    "        create an three array of [n_class, n_bins]\n",
    "        -> Number of prediciton array for that specification\n",
    "        -> Number of correct prediction for that class\n",
    "        -> Percentge of correct \n",
    "        '''\n",
    "\n",
    "        current_no_pred_tot = torch.zeros(self.n_classes, self.n_bins).cuda()\n",
    "        current_no_acc_tot = torch.zeros(self.n_classes, self.n_bins).cuda()\n",
    "        current_conf_sum_tot = torch.zeros(self.n_classes, self.n_bins).cuda()\n",
    "        \n",
    "\n",
    "        output = torch.softmax(output, dim=1)\n",
    "        # [batch, classes]\n",
    "        \n",
    "        for i, (bin_lower, bin_upper) in enumerate(zip(self.bin_lowers, self.bin_uppers)):\n",
    "            mask = (output> bin_lower) * (output <= bin_upper)\n",
    "\n",
    "            for class_id in range(self.n_classes):\n",
    "\n",
    "\n",
    "                class_mask = mask[:,class_id]\n",
    "\n",
    "                classwise_gt = (target == class_id).long()\n",
    "\n",
    "                current_no_pred_tot[class_id][i] = torch.sum(class_mask)\n",
    "                current_no_acc_tot[class_id][i] = torch.sum(class_mask *  classwise_gt)\n",
    "                current_conf_sum_tot[class_id][i] = torch.sum((output[:,class_id])[class_mask])\n",
    "\n",
    "\n",
    "        self.no_pred_tot += current_no_pred_tot.data\n",
    "        self.no_acc_tot += current_no_acc_tot.data\n",
    "        self.conf_sum_tot += current_conf_sum_tot.data\n",
    "\n",
    "        avg_acc = (current_no_acc_tot)/(current_no_pred_tot + 1e-13)\n",
    "        avg_conf = current_conf_sum_tot / (current_no_pred_tot + 1e-13)\n",
    "        # overall_cceLoss = torch.sum(torch.abs(avg_acc - avg_conf) * (self.no_pred_tot/torch.sum(self.no_pred_tot)))\n",
    "        # overall_cceLoss = torch.sum(((avg_acc - avg_conf)**2))\n",
    "\n",
    "        assert (self.loss_type==\"sce\" or self.loss_type==\"kernel\" or self.loss_type==\"diff\")\n",
    "\n",
    "        # Correct implementation\n",
    "        if(self.loss_type==\"sce\"):\n",
    "            overall_cceLoss = torch.sum(torch.abs(avg_acc - avg_conf) * current_no_pred_tot/torch.sum(current_no_pred_tot))\n",
    "\n",
    "        # Kernel based implementation\n",
    "        elif(self.loss_type==\"kernel\"):\n",
    "            overall_cceLoss = torch.sum((1-torch.exp((-1*((avg_acc - avg_conf)**2))/0.5)) * (current_no_pred_tot/torch.sum(current_no_pred_tot)))\n",
    "            \n",
    "        # difference based approach\n",
    "        elif(self.loss_type==\"diff\"):\n",
    "            overall_cceLoss = torch.sum(((avg_acc - avg_conf)**2))\n",
    "\n",
    "        # overall_cceLoss = torch.sum(12500*(1-torch.exp((-1*((avg_acc - avg_conf)**2))/6400)) * (self.no_pred_tot/torch.sum(self.no_pred_tot)))\n",
    "        # print(self.conf_sum_tot.requires_grad)\n",
    "        return overall_cceLoss\n",
    "\n",
    "    def createBins(self):\n",
    "\n",
    "        #uniform bin spacing\n",
    "        \n",
    "        bin_boundaries = np.linspace(0, 1, self.n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "        self.avg_bin = torch.Tensor((self.bin_lowers + self.bin_uppers)/2).cuda()\n",
    "        \n",
    "\n",
    "    def get_perc_table(self, classes):\n",
    "        self.perc = (self.no_acc_tot)/(self.no_pred_tot + 1e-13)\n",
    "        self.perc *= 100\n",
    "        \n",
    "        from tabulate import tabulate\n",
    "        x= list(self.perc.cpu().numpy())\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            x[i]=list(x[i])\n",
    "            x[i]=[classes[i]]+list(x[i])\n",
    "        print(tabulate(x, headers = [\"Classes\"]+[ \"{:0.2f} - {:0.2f}\".format(self.bin_lowers[i] * 100, self.bin_uppers[i] * 100) for i in range( len(self.bin_lowers))]))\n",
    "        \n",
    "        return self.perc\n",
    "\n",
    "    def get_diff_score(self):\n",
    "        avg_acc = (self.no_acc_tot)/(self.no_pred_tot + 1e-13)\n",
    "        avg_conf = self.conf_sum_tot / (self.no_pred_tot + 1e-13)\n",
    "        return torch.sum (torch.abs(avg_acc-avg_conf))/(self.n_bins*self.n_classes)\n",
    "\n",
    "    def get_overall_CCELoss(self):\n",
    "        avg_acc = (self.no_acc_tot)/(self.no_pred_tot + 1e-13)\n",
    "        avg_conf = self.conf_sum_tot / (self.no_pred_tot + 1e-13)\n",
    "        # overall_cceLoss = torch.sum(torch.abs(avg_acc - avg_conf) * (self.no_pred_tot/torch.sum(self.no_pred_tot)))\n",
    "        # overall_cceLoss = torch.sum(((avg_acc - avg_conf)**2))\n",
    "\n",
    "        # Correct implementation\n",
    "        # overall_cceLoss = torch.sum(((avg_acc - avg_conf)**2) * (self.no_pred_tot/torch.sum(self.no_pred_tot)))\n",
    "\n",
    "        # Non Squared  implementation\n",
    "        overall_cceLoss = torch.sum((torch.abs(avg_acc - avg_conf)) * (self.no_pred_tot/torch.sum(self.no_pred_tot)))\n",
    "\n",
    "        # Kernel based implementation\n",
    "        # overall_cceLoss = torch.sum((1-torch.exp((-1*((avg_acc - avg_conf)**2))/0.5)) * (self.no_pred_tot/torch.sum(self.no_pred_tot)))\n",
    "        # overall_cceLoss = torch.sum(12500*(1-torch.exp((-1*((avg_acc - avg_conf)**2))/6400)) * (self.no_pred_tot/torch.sum(self.no_pred_tot)))\n",
    "\n",
    "        # print(\"Overall CCE Loss = \", overall_cceLoss)\n",
    "\n",
    "        return overall_cceLoss\n",
    "\n",
    "        \n",
    "    def get_classVise_CCELoss(self, classes):\n",
    "        avg_acc = (self.no_acc_tot)/(self.no_pred_tot + 1e-13)\n",
    "        # print(avg_acc.shape)\n",
    "        avg_conf = self.conf_sum_tot / (self.no_pred_tot + 1e-13)\n",
    "        # print(avg_conf.shape)\n",
    "\n",
    "        x = torch.sum(torch.abs(avg_acc-avg_conf) * self.no_pred_tot, dim = 1) / torch.sum(self.no_pred_tot, dim = 1)\n",
    "        x = x.reshape(-1,1)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        x=list(x)\n",
    "        from tabulate import tabulate\n",
    "        for i in range(len(x)):\n",
    "            x[i]=list(x[i])\n",
    "            x[i]=[classes[i]]+list(x[i])\n",
    "        print(tabulate(x, headers = [\"Classes\", \"ECELoss\"]))\n",
    "\n",
    "    def get_diff_mean_std (self):\n",
    "        self.perc = (self.no_acc_tot)/(self.no_pred_tot + 1e-13)\n",
    "        avg_conf = self.conf_sum_tot / (self.no_pred_tot + 1e-13)\n",
    "        self.perc *= 100\n",
    "        avg_conf *= 100\n",
    "        dif = torch.abs(avg_conf- self.perc)\n",
    "        return dif.mean(), dif.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "model = resnet32(num_classes= num_classes)\n",
    "resume = \"checkpoint.pth\"\n",
    "saved_model_dict = torch.load(resume)\n",
    "model.load_state_dict(saved_model_dict['state_dict'])\n",
    "model.cuda()\n",
    "sce_criterion = CCELossFast(n_classes = num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing dataset\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "dataloader = datasets.CIFAR10\n",
    "\n",
    "testset = dataloader(root='./data', train=False, download=False, transform=transform_test)\n",
    "testloader = data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 79/79 [00:03<00:00, 22.21it/s]\n",
      "0.035657722502946854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "bar = tqdm(testloader, total=len(testloader))\n",
    "\n",
    "sce_criterion.reset()\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in bar:\n",
    "        targets = targets.cuda()\n",
    "        inputs = inputs.cuda()\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        sce_criterion.forward(outputs, targets)\n",
    "\n",
    "\n",
    "sce = sce_criterion.get_overall_CCELoss().item()\n",
    "print()\n",
    "print(sce)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}